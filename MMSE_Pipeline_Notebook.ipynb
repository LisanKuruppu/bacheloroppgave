{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8187f971",
   "metadata": {},
   "source": [
    "### üß™ 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "d7f6914d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
=======
   "execution_count": 10,
   "id": "d7f6914d",
   "metadata": {},
   "outputs": [],
>>>>>>> 380dca0 (Embeddings)
   "source": [
    "import pandas as pd\n",
    "import Logistic_bootstrap_metrics as lbm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9a001",
   "metadata": {},
   "source": [
    "### üì• 2. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 11,
>>>>>>> 380dca0 (Embeddings)
   "id": "5343dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/TrainTest_Table.csv\"\n",
    "train_test_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268e334",
   "metadata": {},
   "source": [
    "### üìö 3. Define MMSE Question Mapping"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 12,
>>>>>>> 380dca0 (Embeddings)
   "id": "27308224",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmse_questions = {\n",
    "    \"MMYEAR\": \"What year is it?\",\n",
    "    \"MMMONTH\": \"What month is it?\",\n",
    "    \"MMDAY\": \"What day of the week is it?\",\n",
    "    \"MMSEASON\": \"What season is it?\",\n",
    "    \"MMDATE\": \"What is today‚Äôs date?\",\n",
    "    \"MMSTATE\": \"What state are we in?\",\n",
    "    \"MMCITY\": \"What city are we in?\",\n",
    "    \"MMAREA\": \"What county are we in?\",\n",
    "    \"MMHOSPIT\": \"What building are we in?\",\n",
    "    \"MMFLOOR\": \"What floor are we on?\",\n",
<<<<<<< HEAD
    "    \"WORD1\": \"Repeat the word.\",\n",
    "    \"WORD2\": \"Repeat the word.\",\n",
    "    \"WORD3\": \"Repeat the word.\",\n",
=======
    "    \"WORD1\": \"Repeat this word: Ball.\",\n",
    "    \"WORD2\": \"Repeat this word: Flag.\",\n",
    "    \"WORD3\": \"Repeat this word: Tree.\",\n",
>>>>>>> 380dca0 (Embeddings)
    "    \"MMD\": \"Count backward from 100 by 7s.\",\n",
    "    \"MML\": \"Count backward from 100 by 7s.\",\n",
    "    \"MMR\": \"Count backward from 100 by 7s.\",\n",
    "    \"MMO\": \"Count backward from 100 by 7s.\",\n",
    "    \"MMW\": \"Count backward from 100 by 7s.\",\n",
    "    \"MMLTR1\": \"Spell the word 'WORLD' backward.\",\n",
    "    \"MMLTR2\": \"Spell the word 'WORLD' backward.\",\n",
    "    \"MMLTR3\": \"Spell the word 'WORLD' backward.\",\n",
    "    \"MMLTR4\": \"Spell the word 'WORLD' backward.\",\n",
    "    \"MMLTR5\": \"Spell the word 'WORLD' backward.\",\n",
    "    \"WORD1DL\": \"Can you recall the first word from earlier?\",\n",
    "    \"WORD2DL\": \"Can you recall the second word from earlier?\",\n",
    "    \"WORD3DL\": \"Can you recall the third word from earlier?\",\n",
    "    \"MMWATCH\": \"What is this object? (Watch)\",\n",
    "    \"MMPENCIL\": \"What is this object? (Pencil)\",\n",
    "    \"MMREPEAT\": \"Repeat after me: 'No ifs, ands, or buts.'\",\n",
    "    \"MMHAND\": \"Take this paper in your right hand.\",\n",
    "    \"MMFOLD\": \"Fold this paper in half.\",\n",
    "    \"MMONFLR\": \"Place this paper on the floor.\",\n",
    "    \"MMREAD\": \"Read this sentence aloud.\",\n",
    "    \"MMWRITE\": \"Write a sentence.\",\n",
    "    \"MMDRAW\": \"Copy this design.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a662a",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è 4. Generate MMSE Prompts"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 13,
>>>>>>> 380dca0 (Embeddings)
   "id": "97d0f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_structured_mmse_prompts(df, mmse_questions):\n",
    "    prompts = []\n",
    "    for _, row in df.iterrows():\n",
    "        for mmse_var, question in mmse_questions.items():\n",
    "            if mmse_var in df.columns:\n",
    "                score = row[mmse_var]\n",
    "                if not pd.isna(score):\n",
    "                    prompt = (\n",
    "                        f\"Question: {question}\\n\"\n",
    "                        f\"Result: {'Passed (1)' if score == 1 else 'Failed (0)'}\\n\"\n",
    "                    )\n",
    "                    prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "train_df = train_test_df[train_test_df[\"Split\"] == \"Train\"]\n",
    "test_df = train_test_df[train_test_df[\"Split\"] == \"Test\"]\n",
    "\n",
    "structured_mmse_prompts_train = generate_structured_mmse_prompts(train_df, mmse_questions)\n",
    "structured_mmse_prompts_test = generate_structured_mmse_prompts(test_df, mmse_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88bed4",
   "metadata": {},
   "source": [
    "### üíæ 5. Save Prompts to CSV"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 14,
>>>>>>> 380dca0 (Embeddings)
   "id": "3cac6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prompts_train = pd.DataFrame(structured_mmse_prompts_train, columns=[\"MMSE Prompt\"])\n",
    "df_prompts_test = pd.DataFrame(structured_mmse_prompts_test, columns=[\"MMSE Prompt\"])\n",
    "\n",
    "df_prompts_train.to_csv(\"data/MMSE_Prompts_Train.csv\", index=False)\n",
    "df_prompts_test.to_csv(\"data/MMSE_Prompts_Test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ebe68",
   "metadata": {},
   "source": [
    "### ü§ñ 6. Load Bio_ClinicalBERT and Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 35,
>>>>>>> 380dca0 (Embeddings)
   "id": "5cfd2050",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m train_prompts \u001b[38;5;241m=\u001b[39m df_prompts_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMMSE Prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     15\u001b[0m test_prompts \u001b[38;5;241m=\u001b[39m df_prompts_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMMSE Prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 17\u001b[0m train_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mextract_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m test_embeddings \u001b[38;5;241m=\u001b[39m extract_embeddings(test_prompts, model, tokenizer)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Save the embeddings as a coloumn in the promts dataframes\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m, in \u001b[0;36mextract_embeddings\u001b[0;34m(texts, model, tokenizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m     10\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
=======
     "name": "stdout",
     "output_type": "stream",
     "text": []
>>>>>>> 380dca0 (Embeddings)
    }
   ],
   "source": [
    "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "def extract_embeddings(texts, model, tokenizer):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
<<<<<<< HEAD
    "    embeddings = outputs.last_hidden_state[-1]\n",
    "    embeddings = embeddings[0,0,:]\n",
    "    return embeddings.squeeze().numpy()\n",
    "\n",
=======
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.squeeze().numpy()\n",
    "\n",
    "\n",
>>>>>>> 380dca0 (Embeddings)
    "train_prompts = df_prompts_train[\"MMSE Prompt\"].tolist()\n",
    "test_prompts = df_prompts_test[\"MMSE Prompt\"].tolist()\n",
    "\n",
    "train_embeddings = extract_embeddings(train_prompts, model, tokenizer)\n",
    "test_embeddings = extract_embeddings(test_prompts, model, tokenizer)\n",
    "\n",
    "# Save the embeddings as a coloumn in the promts dataframes\n",
    "df_prompts_train[\"Embedding\"] = list(train_embeddings)\n",
    "df_prompts_test[\"Embedding\"] = list(test_embeddings)\n",
    "\n",
    "df_prompts_train.to_csv(\"data/MMSE_Prompts_Train.csv\", index=False)\n",
    "df_prompts_test.to_csv(\"data/MMSE_Prompts_Test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f0fe9",
   "metadata": {},
   "source": [
    "### üìä 7. Prepare Data for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "id": "7a74f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"Group\"].values\n",
    "y_test = test_df[\"Group\"].values\n",
=======
   "execution_count": 2,
   "id": "7a74f9aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIAGNOSIS\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      2\u001b[0m y_test \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIAGNOSIS\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      4\u001b[0m train_embeddings_flat \u001b[38;5;241m=\u001b[39m train_embeddings\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "y_train = train_df[\"DIAGNOSIS\"].values\n",
    "y_test = test_df[\"DIAGNOSIS\"].values\n",
>>>>>>> 380dca0 (Embeddings)
    "\n",
    "train_embeddings_flat = train_embeddings.mean(axis=1)\n",
    "test_embeddings_flat = test_embeddings.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4a415",
   "metadata": {},
   "source": [
    "### üìà 8. Train and Evaluate Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 1,
>>>>>>> 380dca0 (Embeddings)
   "id": "54b192dc",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train: (801,)\n",
      "Shape of train_embeddings_flat: (24030, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "endog and exog matrices are different sizes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of y_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of train_embeddings_flat: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_embeddings_flat\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m model, summary, OR_results \u001b[38;5;241m=\u001b[39m \u001b[43mlbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_logistic_regression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_embeddings_flat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Since train_embeddings_flat is now 2-dimensional with a single feature\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m y_pred_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(sm\u001b[38;5;241m.\u001b[39madd_constant(test_embeddings_flat))\n\u001b[1;32m     16\u001b[0m auc, bal_acc, sensitivity, specificity, f1 \u001b[38;5;241m=\u001b[39m lbm\u001b[38;5;241m.\u001b[39mcompute_metrics(y_test, y_pred_probs)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversitetetiStavanger/Semester6/bacheloroppgave/Logistic_bootstrap_metrics.py:13\u001b[0m, in \u001b[0;36mfit_logistic_regression\u001b[0;34m(df, independent_vars, dep_var)\u001b[0m\n\u001b[1;32m     10\u001b[0m X \u001b[38;5;241m=\u001b[39m df[independent_vars]\n\u001b[1;32m     11\u001b[0m X \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X)  \u001b[38;5;66;03m# Add intercept\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLogit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdep_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit(disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Suppress output\u001b[39;00m\n\u001b[1;32m     15\u001b[0m summary \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msummary()  \u001b[38;5;66;03m# Full statsmodels summary\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Extract ORs and their 95% CI\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/discrete/discrete_model.py:475\u001b[0m, in \u001b[0;36mBinaryModel.__init__\u001b[0;34m(self, endog, exog, offset, check_rank, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;66;03m# unconditional check, requires no extra kwargs added by subclasses\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_kwargs(kwargs)\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, MultinomialModel):\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/discrete/discrete_model.py:185\u001b[0m, in \u001b[0;36mDiscreteModel.__init__\u001b[0;34m(self, endog, exog, check_rank, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, check_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_rank \u001b[38;5;241m=\u001b[39m check_rank\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraise_on_perfect_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# keep for backwards compat\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_extra \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/base/model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/base/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/base/model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/base/data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/base/data.py:89\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_constant(hasconst)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_integrity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/base/data.py:534\u001b[0m, in \u001b[0;36mPandasData._check_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    531\u001b[0m         (\u001b[38;5;28mhasattr\u001b[39m(endog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(exog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog\u001b[38;5;241m.\u001b[39mindex)):\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe indices for endog and exog are not aligned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 534\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_integrity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/base/data.py:436\u001b[0m, in \u001b[0;36mModelData._check_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog):\n\u001b[0;32m--> 436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendog and exog matrices are different sizes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: endog and exog matrices are different sizes"
=======
     "ename": "NameError",
     "evalue": "name 'train_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Reshape the embeddings to be 2-dimensional\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_embeddings_flat \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_embeddings\u001b[49m\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_embeddings_flat \u001b[38;5;241m=\u001b[39m test_embeddings\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Print shapes for debugging\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_embeddings' is not defined"
>>>>>>> 380dca0 (Embeddings)
     ]
    }
   ],
   "source": [
    "# Reshape the embeddings to be 2-dimensional\n",
    "train_embeddings_flat = train_embeddings.mean(axis=1).reshape(-1, 1)\n",
    "test_embeddings_flat = test_embeddings.mean(axis=1).reshape(-1, 1)\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of train_embeddings_flat: {train_embeddings_flat.shape}\")\n",
    "\n",
    "model, summary, OR_results = lbm.fit_logistic_regression(\n",
    "    pd.DataFrame(train_embeddings_flat),\n",
    "    [0],  # Since train_embeddings_flat is now 2-dimensional with a single feature\n",
    "    y_train\n",
    ")\n",
    "\n",
    "y_pred_probs = model.predict(sm.add_constant(test_embeddings_flat))\n",
    "auc, bal_acc, sensitivity, specificity, f1 = lbm.compute_metrics(y_test, y_pred_probs)\n",
    "\n",
    "print(f\"ROC-AUC: {auc:.4f}\")\n",
    "print(f\"Balanced Accuracy: {bal_acc:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
